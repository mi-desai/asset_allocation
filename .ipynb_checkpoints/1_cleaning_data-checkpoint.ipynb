{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from functools import reduce\n",
    "    import os\n",
    "    \n",
    "    result = pd.DataFrame([])\n",
    "    data = pd.read_excel('asset_data.xlsx')\n",
    "    \n",
    "    date_cols = []\n",
    "    asset_cols = []\n",
    "    series = []\n",
    "        \n",
    "    # useful to make a scalable procedure for a single sheet a potentially large number of alternating columns of dates and prices\n",
    "    # push all date columns in the same list, all date_cols are even, so use a modulo-division rule to separate out the dates and prices\n",
    "    # push all asset columns in the same list\n",
    "    \n",
    "    for column_label in enumerate(data.columns):\n",
    "        if column_label[0] % 2 == 0:\n",
    "            date_cols.append(column_label[1])\n",
    "        else:\n",
    "            asset_cols.append(column_label[1])\n",
    "    \n",
    "    for column in enumerate(date_cols):\n",
    "        data['Date' + str(column[0] + 1)] = pd.to_datetime(data[column[1]])\n",
    "        data.drop(column[1], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    for asset in enumerate(asset_cols):\n",
    "        columns = data.columns\n",
    "        modifier = len(asset_cols)\n",
    "        asset_label = asset[1]\n",
    "        date_label = columns[asset[0] + modifier]\n",
    "        new_series = pd.DataFrame(data[[date_label, asset_label]]).set_index(date_label).rename_axis(index='Date').sort_index(ascending=False)\n",
    "        series.append(new_series)\n",
    "    \n",
    "    \n",
    "    # can't use an inner join here because asset price series lengths are not the same, i.e. you are deleting any dates and values that are not in the series of the smallest length\n",
    "    # will write each series to its own csv and read them in separately to chunk out the merge process\n",
    "    \n",
    "    for asset in enumerate(series):\n",
    "        asset[1].to_csv('asset' + str(asset[0]) + '.csv', index=True)\n",
    "    \n",
    "    files = os.listdir()\n",
    "    csvs = []\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            csvs.append(file)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    combined = pd.DataFrame([])\n",
    "    \n",
    "    #for file in enumerate(csvs):\n",
    "    #    reader = pd.read_csv(file[1], chunksize=1000)\n",
    "    #    \n",
    "    #   for r in reader:\n",
    "    #        combine(r)\n",
    "        \n",
    "    \n",
    "    #def combine(x):\n",
    "    #    df = \n",
    "    #combined = reduce(lambda x, y: pd.merge(x, y, on = 'Date'), series)\n",
    "    #print(combined.shape)\n",
    "    #combined.to_excel('combined.xlsx', index=True)\n",
    "    \n",
    "    #combined.plot(subplots=True, figsize=(30, 20))\n",
    "    \n",
    "    \n",
    "    \n",
    "clean_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
